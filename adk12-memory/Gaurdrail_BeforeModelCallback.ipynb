{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a9ca3d7-6e02-442c-89bc-d534dce515f7",
   "metadata": {},
   "source": [
    "## **<font color=\"red\">Before Model Callback</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a225c61f-e6e0-4ca4-94d1-0e99363f0d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "USER: Write a short joke.\n",
      "\n",
      "[Callback] Agent: ModelCallbackAgent\n",
      "[Callback] Last user message: Write a short joke.\n",
      "[Callback] System instruction modified\n",
      "[Callback] Proceeding to model\n",
      "AGENT: Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "USER: Write a joke on BLOCK\n",
      "\n",
      "[Callback] Agent: ModelCallbackAgent\n",
      "[Callback] Last user message: Write a joke on BLOCK\n",
      "[Callback] System instruction modified\n",
      "[Callback] BLOCK detected → Skipping model call\n",
      "AGENT: LLM call was blocked by before_model_callback.\n",
      "\n",
      "USER: Tell me something motivational.\n",
      "\n",
      "[Callback] Agent: ModelCallbackAgent\n",
      "[Callback] Last user message: Tell me something motivational.\n",
      "[Callback] System instruction modified\n",
      "[Callback] Proceeding to model\n",
      "AGENT: LLM call was blocked by before_model_callback.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Guardrail App with before_model_callback (Robust Version)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "from typing import Optional\n",
    "\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.agents.callback_context import CallbackContext\n",
    "from google.adk.models import LlmResponse, LlmRequest\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai import types\n",
    "\n",
    "from config import config\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Environment Setup\n",
    "# ------------------------------------------------------------\n",
    "os.environ[\"GOOGLE_API_KEY\"] = config.GOOGLE_API_KEY\n",
    "\n",
    "APP_NAME = \"guardrail_app\"\n",
    "USER_ID = \"user_1\"\n",
    "SESSION_ID = \"session_001\"\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-flash\"\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# BEFORE MODEL CALLBACK (Fixed Safely)\n",
    "# ------------------------------------------------------------\n",
    "def simple_before_model_modifier(\n",
    "    callback_context: CallbackContext,\n",
    "    llm_request: LlmRequest\n",
    ") -> Optional[LlmResponse]:\n",
    "\n",
    "    print(f\"\\n[Callback] Agent: {callback_context.agent_name}\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Extract last user message\n",
    "    # --------------------------------------------------------\n",
    "    last_user_message = \"\"\n",
    "    if llm_request.contents and llm_request.contents[-1].role == \"user\":\n",
    "        if llm_request.contents[-1].parts:\n",
    "            last_user_message = llm_request.contents[-1].parts[0].text\n",
    "\n",
    "    print(f\"[Callback] Last user message: {last_user_message}\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Handle system instruction safely (str OR Content)\n",
    "    # --------------------------------------------------------\n",
    "    original_instruction = llm_request.config.system_instruction\n",
    "\n",
    "    prefix = \"[Modified by Callback] \"\n",
    "\n",
    "    # Case 1: If instruction is string\n",
    "    if isinstance(original_instruction, str):\n",
    "        modified_instruction = prefix + original_instruction\n",
    "        llm_request.config.system_instruction = modified_instruction\n",
    "\n",
    "    # Case 2: If instruction is Content\n",
    "    elif isinstance(original_instruction, types.Content):\n",
    "        if not original_instruction.parts:\n",
    "            original_instruction.parts = [types.Part(text=\"\")]\n",
    "\n",
    "        original_text = original_instruction.parts[0].text or \"\"\n",
    "        original_instruction.parts[0].text = prefix + original_text\n",
    "        llm_request.config.system_instruction = original_instruction\n",
    "\n",
    "    # Case 3: If None\n",
    "    else:\n",
    "        llm_request.config.system_instruction = prefix\n",
    "\n",
    "    print(\"[Callback] System instruction modified\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # BLOCK Logic\n",
    "    # --------------------------------------------------------\n",
    "    if \"BLOCK\" in last_user_message.upper():\n",
    "        print(\"[Callback] BLOCK detected → Skipping model call\")\n",
    "\n",
    "        return LlmResponse(\n",
    "            content=types.Content(\n",
    "                role=\"model\",\n",
    "                parts=[\n",
    "                    types.Part(\n",
    "                        text=\"LLM call was blocked by before_model_callback.\"\n",
    "                    )\n",
    "                ],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    print(\"[Callback] Proceeding to model\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Create Agent\n",
    "# ------------------------------------------------------------\n",
    "my_llm_agent = LlmAgent(\n",
    "    name=\"ModelCallbackAgent\",\n",
    "    model=MODEL_NAME,\n",
    "    instruction=\"You are a helpful assistant.\",\n",
    "    description=\"Demonstrates before_model_callback\",\n",
    "    before_model_callback=simple_before_model_modifier,\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Setup Session + Runner\n",
    "# ------------------------------------------------------------\n",
    "async def setup():\n",
    "    session_service = InMemorySessionService()\n",
    "\n",
    "    await session_service.create_session(\n",
    "        app_name=APP_NAME,\n",
    "        user_id=USER_ID,\n",
    "        session_id=SESSION_ID\n",
    "    )\n",
    "\n",
    "    runner = Runner(\n",
    "        agent=my_llm_agent,\n",
    "        app_name=APP_NAME,\n",
    "        session_service=session_service\n",
    "    )\n",
    "\n",
    "    return runner\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Call Agent\n",
    "# ------------------------------------------------------------\n",
    "async def call_agent(runner: Runner, query: str):\n",
    "    print(f\"\\nUSER: {query}\")\n",
    "\n",
    "    content = types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[types.Part(text=query)]\n",
    "    )\n",
    "\n",
    "    events = runner.run_async(\n",
    "        user_id=USER_ID,\n",
    "        session_id=SESSION_ID,\n",
    "        new_message=content\n",
    "    )\n",
    "\n",
    "    async for event in events:\n",
    "        if event.is_final_response():\n",
    "            print(\"AGENT:\", event.content.parts[0].text)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Main\n",
    "# ------------------------------------------------------------\n",
    "async def main():\n",
    "    runner = await setup()\n",
    "\n",
    "    await call_agent(runner, \"Write a short joke.\")\n",
    "    await call_agent(runner, \"Write a joke on BLOCK\")\n",
    "    await call_agent(runner, \"Tell me something motivational.\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Entry\n",
    "# ------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # asyncio.run(main())\n",
    "    await main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd70c03-464e-4231-8810-3aa2cdd7fd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
