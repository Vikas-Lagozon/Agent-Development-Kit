{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f4303e8-575a-4637-b52f-bbfa2ac57108",
   "metadata": {},
   "source": [
    "# **<font color=\"red\">Agents Workflow</font>**\n",
    "- Specialized agents that control the execution flow of its sub-agents.\n",
    "1. `Sequential Agent`\n",
    "2. `Loop Agent`\n",
    "3. `Parallel Agent`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9087c3d-deb6-4d96-9c40-fa85c2adf353",
   "metadata": {},
   "source": [
    "## **<font color=\"blue\">Sequential Agents</font>**\n",
    "- Then `SequentialAgent` is a workflow agent that executes its sub-agents in the order they are specified in the list. Use the `SequentialAgent` when you want the execution to occur in a fixed, strict order.\n",
    "- As with other workflow agents, the `SequentialAgent` is not powered by an LLM, and is thus deterministic in how it executes. That being said, workflow agents are concerned only with their execution (i.e. in sequence), and not their internal logic; the tools or sub-agents of a workflow agent may or may not utilize LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca93e46f-2fdb-4d1c-b9e8-23193b70ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from config import config\n",
    "from google.adk.agents.llm_agent import LlmAgent\n",
    "from google.adk.agents.sequential_agent import SequentialAgent\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = config.GOOGLE_API_KEY\n",
    "\n",
    "MODEL = \"gemini-2.5-flash\"\n",
    "APP_NAME = \"sequential_agent\"\n",
    "USER_ID = \"user_1\"\n",
    "SESSION_ID = \"session_001\"\n",
    "\n",
    "# --- 1. Define Sub-Agents for Each Pipeline Stage ---\n",
    "\n",
    "# Code Writer Agent\n",
    "# Takes the initial specification (from user query) and writes code.\n",
    "code_writer_agent = LlmAgent(\n",
    "    name=\"CodeWriterAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"\n",
    "    You are a Python Code Generator.\n",
    "    Based *only* on the user's request, write Python code that fulfills the requirement.\n",
    "    Output *only* the complete Python code block, enclosed in triple backticks (```python ... ```).\n",
    "    Do not add any other text before or after the code block.\n",
    "    \"\"\",\n",
    "    description=\"Writes initial Python code based on a specification.\",\n",
    "    output_key=\"generated_code\"\n",
    ")\n",
    "\n",
    "# Code Reviewer Agent\n",
    "# Takes the code generated by the previous agent (read from state) and provides feedback.\n",
    "code_reviewer_agent = LlmAgent(\n",
    "    name=\"CodeReviewerAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"\n",
    "    You are an expert Python Code Reviewer.\n",
    "    Your task is to provide constructive feedback on the provided code.\n",
    "\n",
    "    **Code to Review:**\n",
    "    ```python\n",
    "    {generated_code}\n",
    "    ```\n",
    "\n",
    "    **Review Criteria:**\n",
    "    1.  **Correctness:** Does the code work as intended? Are there logic errors?\n",
    "    2.  **Readability:** Is the code clear and easy to understand? Follows PEP 8 style guidelines?\n",
    "    3.  **Efficiency:** Is the code reasonably efficient? Any obvious performance bottlenecks?\n",
    "    4.  **Edge Cases:** Does the code handle potential edge cases or invalid inputs gracefully?\n",
    "    5.  **Best Practices:** Does the code follow common Python best practices?\n",
    "\n",
    "    **Output:**\n",
    "    Provide your feedback as a concise, bulleted list. Focus on the most important points for improvement.\n",
    "    If the code is excellent and requires no changes, simply state: \"No major issues found.\"\n",
    "    Output *only* the review comments or the \"No major issues\" statement.\n",
    "    \"\"\",\n",
    "    description=\"Reviews code and provides feedback.\",\n",
    "    output_key=\"review_comments\"\n",
    ")\n",
    "\n",
    "\n",
    "# Code Refactorer Agent\n",
    "# Takes the original code and the review comments (read from state) and refactors the code.\n",
    "code_refactorer_agent = LlmAgent(\n",
    "    name=\"CodeRefactorerAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"\n",
    "    You are a Python Code Refactoring AI.\n",
    "    Your goal is to improve the given Python code based on the provided review comments.\n",
    "\n",
    "    **Original Code:**\n",
    "    ```python\n",
    "    {generated_code}\n",
    "    ```\n",
    "\n",
    "    **Review Comments:**\n",
    "    {review_comments}\n",
    "\n",
    "    **Task:**\n",
    "    Carefully apply the suggestions from the review comments to refactor the original code.\n",
    "    If the review comments state \"No major issues found,\" return the original code unchanged.\n",
    "    Ensure the final code is complete, functional, and includes necessary imports and docstrings.\n",
    "\n",
    "    **Output:**\n",
    "    Output *only* the final, refactored Python code block, enclosed in triple backticks (```python ... ```).\n",
    "    Do not add any other text before or after the code block.\n",
    "    \"\"\",\n",
    "    description=\"Refactors code based on review comments.\",\n",
    "    output_key=\"refactored_code\"\n",
    ")\n",
    "\n",
    "\n",
    "# --- 2. Create the SequentialAgent ---\n",
    "# This agent orchestrates the pipeline by running the sub_agents in order.\n",
    "code_pipeline_agent = SequentialAgent(\n",
    "    name=\"CodePipelineAgent\",\n",
    "    sub_agents=[code_writer_agent, code_reviewer_agent, code_refactorer_agent],\n",
    "    description=\"Executes a sequence of code writing, reviewing, and refactoring.\",\n",
    ")\n",
    "\n",
    "root_agent = code_pipeline_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6caa3b64-3472-407b-9ea6-183d5e8233df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ðŸ”¬  RESEARCH REPORT PIPELINE\n",
      "ðŸ“Œ  Topic: The impact of large language models on software development\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "ðŸ“š  STAGE 1 â€” Raw Research Notes\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "### Overview / Background\n",
      "Large Language Models (LLMs) are deep learning models trained on vast amounts of text data, enabling them to understand, generate, and process human language. Their application in software development involves leveraging these capabilities to automate, assist, and enhance various stages of the software development lifecycle (SDLC), from requirements gathering and design to coding, testing, deployment, and maintenance. This integration aims to improve productivity, reduce errors, accelerate development cycles, and potentially lower costs.\n",
      "\n",
      "### Key Facts or Statistics\n",
      "*   **Significant Productivity Gains:** Studies and industry reports, such as those by GitHub, indicate that developers using AI-powered coding assistants (often LLM-based) complete tasks significantly faster. For example, GitHub Copilot users completed a specific coding task 55% faster than non-users in an internal study.\n",
      "*   **Widespread Adoption:** A 2023 Stack Overflow developer survey revealed that over 70% of developers are already using or plan to use AI tools in their development process within the year, highlighting rapid integration.\n",
      "*   **Code Generation Accuracy:** While LLMs are powerful, their code generation isn't flawless. While models like GPT-4 can generate syntactically correct code a high percentage of the time, the functional correctness and security often require human oversight, with estimates suggesting around 60-80% of generated code requires some level of modification or debugging.\n",
      "*   **Impact on Code Review:** LLMs are increasingly being used in code review processes to identify bugs, suggest improvements, and ensure adherence to coding standards. This can lead to a reduction in manual review time by up to 20-30% in some contexts, freeing up developers for more complex tasks.\n",
      "*   **Shift in Developer Roles:** The rise of LLMs is prompting a shift in developer roles from pure code writing to more high-level design, architecture, prompt engineering, and code verification/refinement. This reorientation is reflected in changing job descriptions and skill demands.\n",
      "*   **Cost Efficiency Potential:** By automating repetitive coding tasks, generating boilerplate, and assisting in debugging, LLMs have the potential to reduce development costs, though the upfront investment in tools and training, along with potential infrastructure costs for self-hosting, can vary.\n",
      "\n",
      "### Different Perspectives or Schools of Thought\n",
      "*   **The Augmentationists (Productivity Multipliers):** This perspective views LLMs as powerful tools that augment human developers, making them more productive, efficient, and capable. Proponents believe LLMs will handle mundane, repetitive tasks, allowing developers to focus on higher-level problem-solving, architectural design, and creative solutions. They emphasize the collaborative aspect, where LLMs act as intelligent assistants rather than replacements.\n",
      "*   **The Transformationists (Paradigm Shift Advocates):** This school of thought suggests that LLMs will fundamentally transform the nature of software development, leading to new paradigms like \"prompt engineering\" as a core skill, \"no-code/low-code\" development empowered by natural language, and potentially a blurring of lines between product management and development. They foresee a future where natural language becomes the primary interface for software creation, making development accessible to a wider audience and accelerating innovation significantly.\n",
      "*   **The Skeptics/Cautious Optimists (Quality, Security, and Ethical Concerns):** While acknowledging the potential, this group raises concerns about the quality, security, and ethical implications of LLM-generated code. They highlight issues like \"hallucinations\" (incorrect code), vulnerability introduction, intellectual property concerns with training data, and the potential for deskilling developers. They advocate for rigorous testing, robust governance frameworks, and continued human oversight to mitigate risks and ensure responsible adoption.\n",
      "\n",
      "### Notable Recent Developments (Last 2-3 Years)\n",
      "*   **Emergence of Sophisticated Coding Assistants (e.g., GitHub Copilot, Amazon CodeWhisperer):** The past 2-3 years have seen the widespread adoption and continuous improvement of AI pair programmers directly integrated into IDEs, offering real-time code suggestions, completion, and generation based on context.\n",
      "*   **Multimodal LLMs and Agents for Software Development:** Beyond pure text-to-code, models are evolving to understand diagrams, UI mockups, and natural language descriptions to generate software components. The development of AI agents capable of planning, executing, and self-correcting multi-step software development tasks is a significant advancement.\n",
      "*   **Integration into Entire SDLC:** LLMs are moving beyond just code generation to assist in requirements gathering (summarizing user stories), test case generation, debugging, documentation creation, and even deployment script generation, aiming for end-to-end impact.\n",
      "*   **Rise of Open-Source LLMs for Code:** Projects like Code Llama and other open-source alternatives have provided powerful, customizable models specifically fine-tuned for coding tasks, democratizing access and fostering innovation beyond proprietary solutions.\n",
      "*   **Focus on Security and Vulnerability Detection:** With increased code generation, there's a growing emphasis on using LLMs to proactively identify and fix security vulnerabilities in generated or existing code, and on developing techniques to make LLM-generated code more secure by design.\n",
      "\n",
      "### Key Challenges or Open Questions in This Area\n",
      "*   **Ensuring Code Quality and Correctness:** How can we consistently guarantee the functional correctness, efficiency, and robustness of LLM-generated code, especially for complex systems or critical applications?\n",
      "*   **Security Vulnerabilities and \"Hallucinations\":** How can we mitigate the risk of LLMs introducing subtle security flaws or generating factually incorrect code (\"hallucinations\") that are hard for humans to detect?\n",
      "*   **Intellectual Property and Licensing:** What are the legal and ethical implications concerning intellectual property rights when LLMs are trained on vast datasets of existing code and then generate new code? How do licensing agreements apply?\n",
      "*   **Developer Deskilling and Reskilling:** Will heavy reliance on LLMs lead to a decline in fundamental coding skills among developers? How can the industry effectively reskill its workforce to leverage LLMs as powerful tools rather than crutches?\n",
      "*   **Cost and Accessibility:** While LLMs promise productivity, the cost of advanced models (API usage, specialized hardware for self-hosting) can be significant. How can LLM-powered development remain accessible to small teams and individual developers?\n",
      "*   **Explainability and Trust:** How can we ensure transparency and explainability in the code generated by LLMs, especially when debugging complex issues or understanding reasoning behind certain architectural choices? Building trust in AI-generated solutions remains critical.\n",
      "*   **Ethical Considerations and Bias:** How do biases present in the training data manifest in generated code (e.g., promoting certain programming styles, architectural patterns, or even perpetuating discriminatory outcomes)? How can we develop fairness and mitigate bias in LLM-assisted development?\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ðŸ”  STAGE 2 â€” Analysis & Insights\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "1.  **Key Trends**\n",
      "    *   **Rapid Adoption & Integration:** LLM-based tools are seeing widespread and fast adoption, becoming integral to developer workflows, with over 70% of developers already using or planning to use AI tools.\n",
      "    *   **SDLC Expansion:** LLM utility is moving beyond just code generation to encompass the entire Software Development Lifecycle (SDLC), from requirements and design to testing, debugging, documentation, and deployment.\n",
      "    *   **Augmentation & Automation:** There's a clear trend towards LLMs augmenting human developers, significantly boosting productivity (e.g., 55% faster task completion) and automating repetitive tasks, freeing developers for higher-level work.\n",
      "    *   **Evolving Capabilities:** Models are becoming more sophisticated, incorporating multimodal understanding (diagrams, UI) and evolving into autonomous agents capable of multi-step problem-solving.\n",
      "    *   **Shifting Developer Roles:** The industry is witnessing a reorientation of developer skills towards high-level design, architecture, prompt engineering, and code verification, rather than pure code writing.\n",
      "    *   **Security & Open-Source Focus:** Increased emphasis on leveraging LLMs for security vulnerability detection and the rise of open-source LLMs for coding tasks are democratizing access and innovation.\n",
      "\n",
      "2.  **Strengths / Opportunities**\n",
      "    *   **Significant Productivity Gains:** Proven ability to accelerate task completion and reduce manual effort in areas like code review, leading to faster development cycles.\n",
      "    *   **Enhanced Cost Efficiency:** Potential for reduced development costs through automation of repetitive tasks and assistance in debugging and boilerplate generation.\n",
      "    *   **Developer Empowerment:** Allows developers to focus on complex problem-solving, architectural design, and innovation by offloading mundane coding.\n",
      "    *   **Broader Accessibility to Development:** The \"Transformationist\" perspective suggests LLMs can enable no-code/low-code paradigms via natural language, expanding access to software creation.\n",
      "    *   **Improved Software Quality (Potentially):** LLMs offer the opportunity to proactively identify bugs and suggest improvements, enhancing code quality and adherence to standards.\n",
      "\n",
      "3.  **Weaknesses / Risks**\n",
      "    *   **Code Quality & Correctness Issues:** LLM-generated code often requires substantial human modification and debugging (60-80%), posing a risk to functional correctness, especially in critical applications.\n",
      "    *   **Security Vulnerabilities & Hallucinations:** High risk of LLMs introducing subtle security flaws or generating factually incorrect code that is difficult for humans to detect.\n",
      "    *   **Intellectual Property & Licensing Ambiguity:** Significant legal and ethical questions surround the IP ownership and licensing implications of code generated from diverse training datasets.\n",
      "    *   **Developer Deskilling:** Over-reliance on LLMs could erode fundamental coding skills, potentially creating a less capable workforce without proper reskilling strategies.\n",
      "    *   **Cost and Accessibility Barriers:** Advanced LLM tools and infrastructure can be expensive, potentially limiting access for smaller teams or individual developers.\n",
      "    *   **Lack of Explainability & Trust:** The opaque nature of LLM decisions hinders debugging and understanding, making it difficult to build full trust in AI-generated solutions.\n",
      "    *   **Ethical Concerns & Bias Propagation:** Potential for LLMs to perpetuate biases from their training data, leading to discriminatory or sub-optimal code outcomes.\n",
      "\n",
      "4.  **Knowledge Gaps**\n",
      "    *   **Reliable Quality Assurance Frameworks:** No clear consensus on how to consistently guarantee the functional correctness, efficiency, and robustness of LLM-generated code across all use cases.\n",
      "    *   **Robust Security Mitigation Strategies:** A lack of definitive solutions for reliably preventing and detecting subtle security flaws and \"hallucinations\" introduced by LLMs.\n",
      "    *   **Legal & Ethical Precedents for IP:** Undefined legal and ethical frameworks regarding intellectual property rights and licensing for LLM-generated code.\n",
      "    *   **Effective Reskilling Models:** Insufficient understanding of the optimal methods and curricula for reskilling developers to effectively leverage LLMs without compromising foundational skills.\n",
      "    *   **Sustainable Accessibility Models:** Unanswered questions on how to make powerful LLM-powered development tools cost-effective and accessible for all organizational sizes.\n",
      "    *   **Methods for Explainability and Trust-Building:** A need for research into how to ensure transparency and explainability in LLM-generated code to foster developer trust and aid debugging.\n",
      "    *   **Bias Detection & Mitigation Techniques:** Unclear methodologies for effectively identifying, quantifying, and mitigating biases within LLM-generated code stemming from training data.\n",
      "\n",
      "5.  **Actionable Insights**\n",
      "    *   **Strategic Investment with Guardrails:** Decision-makers should strategically invest in LLM-powered tools across the SDLC to capture productivity gains, but simultaneously mandate rigorous human oversight, code reviews, and robust testing protocols to mitigate quality and security risks.\n",
      "    *   **Prioritize Workforce Reskilling & Adaptation:** Develop and implement proactive training programs focused on prompt engineering, high-level design, and critical code verification to empower developers, prevent deskilling, and adapt roles to maximize LLM augmentation.\n",
      "    *   **Establish Clear IP & Security Governance:** Formulate clear internal policies and seek legal counsel regarding intellectual property rights, licensing, and enhanced security audits for LLM-generated code to navigate legal ambiguities and safeguard proprietary assets.\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "âœ…  STAGE 3 â€” Final Report (Markdown)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "# The Impact of Large Language Models on Software Development\n",
      "\n",
      "## Executive Summary\n",
      "Large Language Models (LLMs) are rapidly transforming software development by automating tasks and augmenting developer capabilities across the entire SDLC. While offering significant productivity gains and cost efficiencies, challenges remain regarding code quality, security, intellectual property, and the need for developer reskilling. Strategic investment coupled with robust governance and proactive workforce adaptation will be crucial for harnessing the full potential of LLMs in the software industry.\n",
      "\n",
      "## Background\n",
      "Large Language Models (LLMs) are advanced deep learning models trained on extensive text datasets, enabling them to comprehend, generate, and process human language effectively. In the context of software development, LLMs are being integrated to automate, assist, and enhance various stages of the Software Development Lifecycle (SDLC). This includes areas such as requirements gathering, design, coding, testing, deployment, and ongoing maintenance.\n",
      "\n",
      "The primary objective of this integration is to boost overall productivity, minimize errors, accelerate development cycles, and potentially reduce operational costs. The capabilities of LLMs are poised to redefine traditional development practices, fostering greater efficiency and innovation across the industry.\n",
      "\n",
      "## Key Findings\n",
      "*   **Significant Productivity Gains:** Developers using LLM-powered coding assistants demonstrate substantial efficiency improvements, with studies indicating task completion up to 55% faster.\n",
      "*   **Widespread Adoption:** Over 70% of developers are currently using or planning to adopt AI tools in their development process, signaling rapid industry integration.\n",
      "*   **Code Generation Requires Oversight:** While LLMs generate syntactically correct code, 60-80% of generated code often requires human modification or debugging for functional correctness and security.\n",
      "*   **Reduced Code Review Time:** LLMs are streamlining code review processes, potentially reducing manual review time by 20-30% by identifying bugs and suggesting improvements.\n",
      "*   **Shifting Developer Roles:** LLMs are prompting a reorientation of developer responsibilities towards higher-level design, architecture, prompt engineering, and code verification, moving away from pure code writing.\n",
      "*   **Cost Efficiency Potential:** Automation of repetitive tasks, boilerplate generation, and debugging assistance offered by LLMs have the potential to reduce overall development costs.\n",
      "*   **Evolving Capabilities & SDLC Integration:** Recent advancements include sophisticated coding assistants (e.g., GitHub Copilot, Amazon CodeWhisperer), multimodal LLMs, and AI agents capable of multi-step problem-solving, with LLMs integrating across the entire SDLC, from requirements to deployment.\n",
      "*   **Rise of Open-Source LLMs:** The emergence of open-source LLMs specifically fine-tuned for coding tasks (e.g., Code Llama) is democratizing access and fostering innovation.\n",
      "*   **Focus on Security:** Increased emphasis is placed on using LLMs to detect and mitigate security vulnerabilities in generated and existing code.\n",
      "\n",
      "## Analysis & Insights\n",
      "\n",
      "**Key Trends:**\n",
      "The software development landscape is experiencing rapid change driven by LLMs. There's a **rapid adoption and integration** of LLM-based tools, with over 70% of developers engaging with AI tools. LLM utility is expanding beyond code generation to an **SDLC expansion**, encompassing requirements, design, testing, and deployment. The prevailing trend is **augmentation and automation**, where LLMs boost productivity and automate repetitive tasks, enabling developers to focus on higher-level work. **Evolving capabilities** include multimodal understanding and autonomous AI agents. This shift is leading to **reorientation of developer roles** towards design, architecture, and prompt engineering, alongside an increased **focus on security and open-source LLMs**.\n",
      "\n",
      "**Strengths / Opportunities:**\n",
      "LLMs present compelling opportunities, including **significant productivity gains**, demonstrated by faster task completion and reduced manual effort in areas like code review. There's potential for **enhanced cost efficiency** through automation and debugging assistance. LLMs **empower developers** by freeing them from mundane tasks, allowing focus on innovation. The \"Transformationist\" perspective suggests **broader accessibility to development** via natural language interfaces (no-code/low-code). Potentially, LLMs can lead to **improved software quality** by proactively identifying bugs and ensuring adherence to coding standards.\n",
      "\n",
      "**Weaknesses / Risks:**\n",
      "Despite the benefits, notable risks exist. **Code quality and correctness issues** are prominent, with 60-80% of generated code often requiring substantial human modification. There's a high risk of **security vulnerabilities and \"hallucinations\"** (incorrect code) being introduced. **Intellectual property and licensing ambiguity** remain significant legal and ethical concerns. Over-reliance on LLMs could lead to **developer deskilling**, necessitating proactive reskilling strategies. **Cost and accessibility barriers** for advanced tools may limit adoption. The **lack of explainability and trust** in LLM decisions poses challenges for debugging and confidence. Finally, **ethical concerns and bias propagation** from training data could lead to sub-optimal or discriminatory code outcomes.\n",
      "\n",
      "**Knowledge Gaps:**\n",
      "Several critical areas lack established solutions. There's no consensus on **reliable quality assurance frameworks** for consistently guaranteeing the functional correctness and robustness of LLM-generated code. **Robust security mitigation strategies** are needed to reliably prevent and detect subtle flaws. Legal and ethical precedents for **intellectual property rights** in LLM-generated code are undefined. Effective **reskilling models** for developers to leverage LLMs without compromising foundational skills are not yet clear. Questions remain about **sustainable accessibility models** for powerful LLM tools for all organizational sizes. Research is needed into **methods for explainability and trust-building** in AI-generated solutions. Finally, methodologies for **bias detection and mitigation techniques** within LLM-generated code are underdeveloped.\n",
      "\n",
      "## Recommendations\n",
      "1.  **Strategic Investment with Guardrails:** Decision-makers should strategically invest in LLM-powered tools across the SDLC to capture productivity gains, but simultaneously mandate rigorous human oversight, code reviews, and robust testing protocols to mitigate quality and security risks.\n",
      "2.  **Prioritize Workforce Reskilling & Adaptation:** Develop and implement proactive training programs focused on prompt engineering, high-level design, and critical code verification to empower developers, prevent deskilling, and adapt roles to maximize LLM augmentation.\n",
      "3.  **Establish Clear IP & Security Governance:** Formulate clear internal policies and seek legal counsel regarding intellectual property rights, licensing, and enhanced security audits for LLM-generated code to navigate legal ambiguities and safeguard proprietary assets.\n",
      "\n",
      "## Conclusion\n",
      "Large Language Models are rapidly reshaping the software development landscape, offering unprecedented opportunities for productivity enhancement and innovation across the entire SDLC. While the benefits are clear, navigating the inherent challenges related to code quality, security, intellectual property, and workforce adaptation will define the success of their widespread integration. A balanced approach of strategic adoption, proactive risk management, and continuous developer empowerment is essential to fully realize the transformative potential of LLMs in software creation.\n",
      "\n",
      "---\n",
      "*Report generated by the Research Report Pipeline.*\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "\n",
    "# --- Google ADK Imports ---\n",
    "from google.adk.agents.llm_agent import LlmAgent\n",
    "from google.adk.agents.sequential_agent import SequentialAgent\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types\n",
    "\n",
    "# --- Configuration ---\n",
    "try:\n",
    "    from config import config\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = config.GOOGLE_API_KEY\n",
    "except ImportError:\n",
    "    if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "        raise EnvironmentError(\n",
    "            \"GOOGLE_API_KEY is not set. \"\n",
    "            \"Either provide a config.py with config.GOOGLE_API_KEY \"\n",
    "            \"or set the environment variable directly.\"\n",
    "        )\n",
    "\n",
    "# --- Constants ---\n",
    "MODEL = \"gemini-2.5-flash\"\n",
    "APP_NAME = \"research_report_pipeline\"\n",
    "USER_ID = \"user_1\"\n",
    "SESSION_ID = \"session_001\"\n",
    "\n",
    "\n",
    "# ===========================================================================\n",
    "# PIPELINE OVERVIEW\n",
    "# ===========================================================================\n",
    "#\n",
    "#   User Topic\n",
    "#       â”‚\n",
    "#       â–¼\n",
    "#  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "#  â”‚  ResearcherAgent    â”‚  â”€â”€ Gathers key facts, stats & perspectives\n",
    "#  â”‚  output_key:        â”‚     on the given topic\n",
    "#  â”‚  \"raw_research\"     â”‚\n",
    "#  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#           â”‚  raw_research â†’ injected into next agent's prompt\n",
    "#           â–¼\n",
    "#  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "#  â”‚  AnalystAgent       â”‚  â”€â”€ Identifies trends, insights & gaps\n",
    "#  â”‚  output_key:        â”‚     from the raw research\n",
    "#  â”‚  \"analysis\"         â”‚\n",
    "#  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#           â”‚  raw_research + analysis â†’ injected into next agent's prompt\n",
    "#           â–¼\n",
    "#  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "#  â”‚  ReportWriterAgent  â”‚  â”€â”€ Produces a clean, structured markdown report\n",
    "#  â”‚  output_key:        â”‚\n",
    "#  â”‚  \"final_report\"     â”‚\n",
    "#  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#\n",
    "# ===========================================================================\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Stage 1 â€” Researcher Agent\n",
    "# ---------------------------------------------------------------------------\n",
    "# Receives: user's topic (from the initial query)\n",
    "# Produces: raw_research  â†’  saved to session state\n",
    "\n",
    "researcher_agent = LlmAgent(\n",
    "    name=\"ResearcherAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"You are a thorough Research Specialist.\n",
    "\n",
    "Your task is to gather comprehensive information on the topic provided by the user.\n",
    "\n",
    "**What to include:**\n",
    "- A brief overview / background of the topic\n",
    "- 5â€“7 key facts or statistics (with context)\n",
    "- 2â€“3 different perspectives or schools of thought\n",
    "- Notable recent developments (last 2â€“3 years if applicable)\n",
    "- Key challenges or open questions in this area\n",
    "\n",
    "**Output format:**\n",
    "Use clear section headers and bullet points.\n",
    "Output *only* the structured research notes â€” no preamble, no conclusion.\n",
    "\"\"\",\n",
    "    description=\"Gathers structured research notes on a given topic.\",\n",
    "    output_key=\"raw_research\",\n",
    ")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Stage 2 â€” Analyst Agent\n",
    "# ---------------------------------------------------------------------------\n",
    "# Receives: raw_research  (injected from session state via {raw_research})\n",
    "# Produces: analysis      â†’  saved to session state\n",
    "\n",
    "analyst_agent = LlmAgent(\n",
    "    name=\"AnalystAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"You are a senior Data & Insights Analyst.\n",
    "\n",
    "You have been given raw research notes. Your job is to analyse them critically.\n",
    "\n",
    "**Raw Research Notes:**\n",
    "{raw_research}\n",
    "\n",
    "**Your analysis must cover:**\n",
    "1. **Key Trends** â€“ What patterns or directions are emerging?\n",
    "2. **Strengths / Opportunities** â€“ What positive signals exist?\n",
    "3. **Weaknesses / Risks** â€“ What concerns or limitations stand out?\n",
    "4. **Knowledge Gaps** â€“ What important questions remain unanswered?\n",
    "5. **Actionable Insights** â€“ What are the 3 most important takeaways for a decision-maker?\n",
    "\n",
    "**Output format:**\n",
    "Use numbered sections matching the five areas above.\n",
    "Be concise and analytical â€” avoid repeating the raw research verbatim.\n",
    "Output *only* the analysis. No preamble or closing remarks.\n",
    "\"\"\",\n",
    "    description=\"Analyses raw research to extract trends, risks, and insights.\",\n",
    "    output_key=\"analysis\",\n",
    ")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Stage 3 â€” Report Writer Agent\n",
    "# ---------------------------------------------------------------------------\n",
    "# Receives: raw_research + analysis  (both injected from session state)\n",
    "# Produces: final_report  â†’  saved to session state\n",
    "\n",
    "report_writer_agent = LlmAgent(\n",
    "    name=\"ReportWriterAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"You are a professional Technical Report Writer.\n",
    "\n",
    "Using the research notes and analysis provided below, write a polished, \n",
    "well-structured research report in Markdown format.\n",
    "\n",
    "**Research Notes:**\n",
    "{raw_research}\n",
    "\n",
    "**Analysis:**\n",
    "{analysis}\n",
    "\n",
    "**Report Structure (strictly follow this):**\n",
    "\n",
    "# [Descriptive Report Title]\n",
    "\n",
    "## Executive Summary\n",
    "A 3â€“4 sentence overview of the entire report.\n",
    "\n",
    "## Background\n",
    "Context and importance of the topic (2â€“3 short paragraphs).\n",
    "\n",
    "## Key Findings\n",
    "Present the most important facts and data points clearly.\n",
    "\n",
    "## Analysis & Insights\n",
    "Summarise the trends, opportunities, risks, and knowledge gaps.\n",
    "\n",
    "## Recommendations\n",
    "3â€“5 concrete, actionable recommendations based on the findings.\n",
    "\n",
    "## Conclusion\n",
    "A brief, forward-looking closing paragraph.\n",
    "\n",
    "---\n",
    "*Report generated by the Research Report Pipeline.*\n",
    "\n",
    "**Rules:**\n",
    "- Use proper Markdown (headers, bold, bullet points where appropriate).\n",
    "- Do not invent facts not present in the research notes or analysis.\n",
    "- Keep the tone professional and objective.\n",
    "- Output *only* the Markdown report â€” no extra commentary.\n",
    "\"\"\",\n",
    "    description=\"Writes a polished Markdown report from research notes and analysis.\",\n",
    "    output_key=\"final_report\",\n",
    ")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# SequentialAgent â€” ties all three stages together\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "research_pipeline_agent = SequentialAgent(\n",
    "    name=\"ResearchReportPipeline\",\n",
    "    sub_agents=[researcher_agent, analyst_agent, report_writer_agent],\n",
    "    description=(\n",
    "        \"A three-stage pipeline that: \"\n",
    "        \"(1) researches a topic, \"\n",
    "        \"(2) analyses the findings, \"\n",
    "        \"(3) writes a formatted report.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Root agent (required by ADK runner)\n",
    "root_agent = research_pipeline_agent\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Session Service & Runner\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "runner = Runner(\n",
    "    agent=root_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service,\n",
    ")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Helper utilities\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def print_section(title: str, content: str, emoji: str = \"ðŸ“„\") -> None:\n",
    "    \"\"\"Pretty-print a pipeline stage output.\"\"\"\n",
    "    width = 60\n",
    "    print(f\"\\n{emoji}  {title}\")\n",
    "    print(\"â”€\" * width)\n",
    "    print(content.strip())\n",
    "    print(\"â”€\" * width)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Core pipeline runner\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "async def run_research_pipeline(topic: str) -> dict:\n",
    "    \"\"\"\n",
    "    Run the full research â†’ analysis â†’ report pipeline for a given topic.\n",
    "\n",
    "    Args:\n",
    "        topic: The subject to research (e.g. \"quantum computing\").\n",
    "\n",
    "    Returns:\n",
    "        A dict with keys: raw_research, analysis, final_report.\n",
    "    \"\"\"\n",
    "    # Fresh session for each run\n",
    "    await session_service.create_session(\n",
    "        app_name=APP_NAME,\n",
    "        user_id=USER_ID,\n",
    "        session_id=SESSION_ID,\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"â•\" * 60)\n",
    "    print(f\"ðŸ”¬  RESEARCH REPORT PIPELINE\")\n",
    "    print(f\"ðŸ“Œ  Topic: {topic}\")\n",
    "    print(\"â•\" * 60)\n",
    "\n",
    "    user_message = types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[types.Part(text=f\"Research topic: {topic}\")],\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Execute the sequential pipeline\n",
    "        # runner.run is synchronous but internally manages async sub-agents\n",
    "        events = list(\n",
    "            runner.run(\n",
    "                user_id=USER_ID,\n",
    "                session_id=SESSION_ID,\n",
    "                new_message=user_message,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Read all stage outputs from session state\n",
    "        session = await session_service.get_session(\n",
    "            app_name=APP_NAME,\n",
    "            user_id=USER_ID,\n",
    "            session_id=SESSION_ID,\n",
    "        )\n",
    "        state = session.state if session else {}\n",
    "\n",
    "        raw_research = state.get(\"raw_research\", \"(not found)\")\n",
    "        analysis     = state.get(\"analysis\",     \"(not found)\")\n",
    "        final_report = state.get(\"final_report\", \"(not found)\")\n",
    "\n",
    "        # â”€â”€ Display each stage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        print_section(\"STAGE 1 â€” Raw Research Notes\", raw_research, \"ðŸ“š\")\n",
    "        print_section(\"STAGE 2 â€” Analysis & Insights\", analysis,    \"ðŸ”\")\n",
    "        print_section(\"STAGE 3 â€” Final Report (Markdown)\", final_report, \"âœ…\")\n",
    "\n",
    "        return {\n",
    "            \"raw_research\": raw_research,\n",
    "            \"analysis\":     analysis,\n",
    "            \"final_report\": final_report,\n",
    "        }\n",
    "\n",
    "    except Exception as exc:\n",
    "        print(f\"\\nâŒ  Pipeline error: {exc}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Optional: save the final report to a .md file\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "async def run_and_save(topic: str, output_path: str = \"report.md\") -> None:\n",
    "    \"\"\"Run the pipeline and save the final Markdown report to disk.\"\"\"\n",
    "    results = await run_research_pipeline(topic)\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(results[\"final_report\"])\n",
    "\n",
    "    print(f\"\\nðŸ’¾  Final report saved to: {output_path}\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Main entry point\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "async def main() -> None:\n",
    "    \"\"\"Run the research pipeline on a sample topic.\"\"\"\n",
    "\n",
    "    # â”€â”€ Change this topic to anything you like â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    topic = \"The impact of large language models on software development\"\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "    await run_research_pipeline(topic)\n",
    "\n",
    "    # Uncomment below to also save the report to a file:\n",
    "    # await run_and_save(topic, output_path=\"llm_software_dev_report.md\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # asyncio.run(main())\n",
    "    await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e426b5-211a-4f81-b645-98ac6d6c238b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
